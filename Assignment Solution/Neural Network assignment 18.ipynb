{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7b0f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5777b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r'/Users/rahulpoojith/Documents/Excelr Datasets/Machine Learning Datasets/Alphabets_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e10f324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c42309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   letter  20000 non-null  object\n",
      " 1   xbox    20000 non-null  int64 \n",
      " 2   ybox    20000 non-null  int64 \n",
      " 3   width   20000 non-null  int64 \n",
      " 4   height  20000 non-null  int64 \n",
      " 5   onpix   20000 non-null  int64 \n",
      " 6   xbar    20000 non-null  int64 \n",
      " 7   ybar    20000 non-null  int64 \n",
      " 8   x2bar   20000 non-null  int64 \n",
      " 9   y2bar   20000 non-null  int64 \n",
      " 10  xybar   20000 non-null  int64 \n",
      " 11  x2ybar  20000 non-null  int64 \n",
      " 12  xy2bar  20000 non-null  int64 \n",
      " 13  xedge   20000 non-null  int64 \n",
      " 14  xedgey  20000 non-null  int64 \n",
      " 15  yedge   20000 non-null  int64 \n",
      " 16  yedgex  20000 non-null  int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c026903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.023550</td>\n",
       "      <td>7.035500</td>\n",
       "      <td>5.121850</td>\n",
       "      <td>5.37245</td>\n",
       "      <td>3.505850</td>\n",
       "      <td>6.897600</td>\n",
       "      <td>7.500450</td>\n",
       "      <td>4.628600</td>\n",
       "      <td>5.178650</td>\n",
       "      <td>8.282050</td>\n",
       "      <td>6.45400</td>\n",
       "      <td>7.929000</td>\n",
       "      <td>3.046100</td>\n",
       "      <td>8.338850</td>\n",
       "      <td>3.691750</td>\n",
       "      <td>7.80120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.913212</td>\n",
       "      <td>3.304555</td>\n",
       "      <td>2.014573</td>\n",
       "      <td>2.26139</td>\n",
       "      <td>2.190458</td>\n",
       "      <td>2.026035</td>\n",
       "      <td>2.325354</td>\n",
       "      <td>2.699968</td>\n",
       "      <td>2.380823</td>\n",
       "      <td>2.488475</td>\n",
       "      <td>2.63107</td>\n",
       "      <td>2.080619</td>\n",
       "      <td>2.332541</td>\n",
       "      <td>1.546722</td>\n",
       "      <td>2.567073</td>\n",
       "      <td>1.61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xbox          ybox         width       height         onpix  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
       "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
       "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
       "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
       "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
       "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
       "\n",
       "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
       "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
       "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
       "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
       "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
       "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
       "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
       "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
       "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
       "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
       "\n",
       "            yedgex  \n",
       "count  20000.00000  \n",
       "mean       7.80120  \n",
       "std        1.61747  \n",
       "min        0.00000  \n",
       "25%        7.00000  \n",
       "50%        8.00000  \n",
       "75%        9.00000  \n",
       "max       15.00000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce97496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65cf450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1332"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab790689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>T</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18668 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19994      T     5     8      7       7      7     7     9      4      8   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19994      7       7       8      3      10      8       6  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[18668 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f514671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18668 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter\n",
       "0          T\n",
       "1          I\n",
       "2          D\n",
       "3          N\n",
       "4          G\n",
       "...      ...\n",
       "19994      T\n",
       "19995      D\n",
       "19996      C\n",
       "19997      T\n",
       "19999      A\n",
       "\n",
       "[18668 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_df = df.select_dtypes(include='object')  ## Find the categorical column\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d927df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18668 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       letter\n",
       "0          19\n",
       "1           8\n",
       "2           3\n",
       "3          13\n",
       "4           6\n",
       "...       ...\n",
       "19994      19\n",
       "19995       3\n",
       "19996       2\n",
       "19997      19\n",
       "19999       0\n",
       "\n",
       "[18668 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "cat_df = cat_df.apply(lambda x: le.fit_transform(x.astype(str)))\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b59305c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: letter, Unique Values: ['T' 'I' 'D' 'N' 'G' 'S' 'B' 'A' 'J' 'M' 'X' 'O' 'R' 'F' 'C' 'H' 'W' 'L'\n",
      " 'P' 'E' 'V' 'Y' 'Q' 'U' 'K' 'Z']\n",
      "Column: xbox, Unique Values: [ 2  5  4  7  1 11  3  6 12  8  9 10 13  0 15 14]\n",
      "Column: ybox, Unique Values: [ 8 12 11  1  2 15  9 13  4 10  3  5  6 14  7  0]\n",
      "Column: width, Unique Values: [ 3  6  5  4 13  8  2  7 11 12  9  1 10  0 15 14]\n",
      "Column: height, Unique Values: [ 5  7  8  6  1  4  2  9  3 11 10  0 12 13 15 14]\n",
      "Column: onpix, Unique Values: [ 1  2  6  3  4  7  9  5 10  8  0 11 14 13 12 15]\n",
      "Column: xbar, Unique Values: [ 8 10  5 13  6  7  3  9  0  4  1 12 11 14  2 15]\n",
      "Column: ybar, Unique Values: [13  5  6  9  8  7  2 11 10  1  4 14  0  3 12 15]\n",
      "Column: x2bar, Unique Values: [ 0  5  2  4  6  3  7  9  1  8 10 13 14 15 12 11]\n",
      "Column: y2bar, Unique Values: [ 6  4  9  2  8  3  5 11  7  1 10  0 13 14 12 15]\n",
      "Column: xybar, Unique Values: [ 6 13 10  4  5  7  8 12 11 14  0  9  3 15  1  2]\n",
      "Column: x2ybar, Unique Values: [10  3  4  5  6  2  1  7  9  8 11  0 12 14 13 15]\n",
      "Column: xy2bar, Unique Values: [ 8  9  7 10  6 11  4 12 14  3 15  5 13  0  2  1]\n",
      "Column: xedge, Unique Values: [ 0  2  3  6  1  8  5  4 10  7  9 11 13 14 12 15]\n",
      "Column: xedgey, Unique Values: [ 8  7 10  6  1  9 12 11  5  4 13  3 14 15  2  0]\n",
      "Column: yedge, Unique Values: [ 0  4  3  2  5  9  7  1  6  8 12 10 13 11 14 15]\n",
      "Column: yedgex, Unique Values: [ 8 10  9  7  6 11  4  5  3 12 13 14  1  2 15  0]\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    unique_vals = df[col].unique()\n",
    "    print(f\"Column: {col}, Unique Values: {unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af919270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_19280\\1414154009.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col + '_encoded'] = le.fit_transform(df[col])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instantiate LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to each categorical column\n",
    "for col in cat_df:\n",
    "    df[col + '_encoded'] = le.fit_transform(df[col])\n",
    "\n",
    "# Drop the original categorical columns if no longer needed\n",
    "df = df.drop(columns=cat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c309e04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  x2ybar  \\\n",
      "0     2     8      3       5      1     8    13      0      6      6      10   \n",
      "1     5    12      3       7      2    10     5      5      4     13       3   \n",
      "2     4    11      6       8      6    10     6      2      6     10       3   \n",
      "3     7    11      6       6      3     5     9      4      6      4       4   \n",
      "4     2     1      3       1      1     8     6      6      6      6       5   \n",
      "\n",
      "   xy2bar  xedge  xedgey  yedge  yedgex  letter_encoded  \n",
      "0       8      0       8      0       8              19  \n",
      "1       9      2       8      4      10               8  \n",
      "2       7      3       7      3       9               3  \n",
      "3      10      6      10      2       8              13  \n",
      "4       9      1       7      5      10               6  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a961add1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "      <th>letter_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18668 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0         2     8      3       5      1     8    13      0      6      6   \n",
       "1         5    12      3       7      2    10     5      5      4     13   \n",
       "2         4    11      6       8      6    10     6      2      6     10   \n",
       "3         7    11      6       6      3     5     9      4      6      4   \n",
       "4         2     1      3       1      1     8     6      6      6      6   \n",
       "...     ...   ...    ...     ...    ...   ...   ...    ...    ...    ...   \n",
       "19994     5     8      7       7      7     7     9      4      8      7   \n",
       "19995     2     2      3       3      2     7     7      7      6      6   \n",
       "19996     7    10      8       8      4     4     8      6      9     12   \n",
       "19997     6     9      6       7      5     6    11      3      7     11   \n",
       "19999     4     9      6       6      2     9     5      3      1      8   \n",
       "\n",
       "       x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  letter_encoded  \n",
       "0          10       8      0       8      0       8              19  \n",
       "1           3       9      2       8      4      10               8  \n",
       "2           3       7      3       7      3       9               3  \n",
       "3           4      10      6      10      2       8              13  \n",
       "4           5       9      1       7      5      10               6  \n",
       "...       ...     ...    ...     ...    ...     ...             ...  \n",
       "19994       7       8      3      10      8       6              19  \n",
       "19995       6       4      2       8      3       7               3  \n",
       "19996       9      13      2       9      3       7               2  \n",
       "19997       9       5      2      12      2       4              19  \n",
       "19999       1       8      2       7      2       8               0  \n",
       "\n",
       "[18668 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0792d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns= ['letter_encoded'])\n",
    "target = df['letter_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b41bd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18668 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
       "0         2     8      3       5      1     8    13      0      6      6   \n",
       "1         5    12      3       7      2    10     5      5      4     13   \n",
       "2         4    11      6       8      6    10     6      2      6     10   \n",
       "3         7    11      6       6      3     5     9      4      6      4   \n",
       "4         2     1      3       1      1     8     6      6      6      6   \n",
       "...     ...   ...    ...     ...    ...   ...   ...    ...    ...    ...   \n",
       "19994     5     8      7       7      7     7     9      4      8      7   \n",
       "19995     2     2      3       3      2     7     7      7      6      6   \n",
       "19996     7    10      8       8      4     4     8      6      9     12   \n",
       "19997     6     9      6       7      5     6    11      3      7     11   \n",
       "19999     4     9      6       6      2     9     5      3      1      8   \n",
       "\n",
       "       x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          10       8      0       8      0       8  \n",
       "1           3       9      2       8      4      10  \n",
       "2           3       7      3       7      3       9  \n",
       "3           4      10      6      10      2       8  \n",
       "4           5       9      1       7      5      10  \n",
       "...       ...     ...    ...     ...    ...     ...  \n",
       "19994       7       8      3      10      8       6  \n",
       "19995       6       4      2       8      3       7  \n",
       "19996       9      13      2       9      3       7  \n",
       "19997       9       5      2      12      2       4  \n",
       "19999       1       8      2       7      2       8  \n",
       "\n",
       "[18668 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6007066c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        19\n",
       "1         8\n",
       "2         3\n",
       "3        13\n",
       "4         6\n",
       "         ..\n",
       "19994    19\n",
       "19995     3\n",
       "19996     2\n",
       "19997    19\n",
       "19999     0\n",
       "Name: letter_encoded, Length: 18668, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3682853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 18668\n",
      "Number of features: 17\n",
      "Class distribution: letter_encoded\n",
      "15    782\n",
      "20    768\n",
      "3     760\n",
      "16    760\n",
      "0     756\n",
      "5     752\n",
      "19    748\n",
      "24    746\n",
      "6     743\n",
      "17    737\n",
      "12    732\n",
      "1     730\n",
      "18    729\n",
      "22    726\n",
      "4     725\n",
      "14    718\n",
      "10    718\n",
      "9     715\n",
      "2     710\n",
      "21    706\n",
      "7     704\n",
      "13    688\n",
      "23    678\n",
      "11    673\n",
      "25    640\n",
      "8     524\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", df.shape[0])\n",
    "print(\"Number of features:\", df.shape[1])\n",
    "print(\"Class distribution:\", df['letter_encoded'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd053f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18668 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   xbox            18668 non-null  int64\n",
      " 1   ybox            18668 non-null  int64\n",
      " 2   width           18668 non-null  int64\n",
      " 3   height          18668 non-null  int64\n",
      " 4   onpix           18668 non-null  int64\n",
      " 5   xbar            18668 non-null  int64\n",
      " 6   ybar            18668 non-null  int64\n",
      " 7   x2bar           18668 non-null  int64\n",
      " 8   y2bar           18668 non-null  int64\n",
      " 9   xybar           18668 non-null  int64\n",
      " 10  x2ybar          18668 non-null  int64\n",
      " 11  xy2bar          18668 non-null  int64\n",
      " 12  xedge           18668 non-null  int64\n",
      " 13  xedgey          18668 non-null  int64\n",
      " 14  yedge           18668 non-null  int64\n",
      " 15  yedgex          18668 non-null  int64\n",
      " 16  letter_encoded  18668 non-null  int32\n",
      "dtypes: int32(1), int64(16)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f6da818",
   "metadata": {},
   "source": [
    "Model Implementation\n",
    "●\tConstruct a basic ANN model using your chosen high-level neural network library. Ensure your model includes at least one hidden layer.\n",
    "●\tDivide the dataset into training and test sets.\n",
    "●\tTrain your model on the training set and then use it to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "704d2ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (3.5.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42211f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f12a48f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30e82537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce932f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f7a3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.5, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89299fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9334, 16)\n",
      "(9334,)\n",
      "(9334, 16)\n",
      "(9334,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64790d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= keras.utils.to_categorical(y_train)\n",
    "y_test= keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b66d2714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0385be9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff21ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "batch_size=1000\n",
    "n_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97d9bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa535d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.early_stopping.EarlyStopping at 0x1a9e3e51290>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop=EarlyStopping(monitor='val_loss',patience=4)\n",
    "early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7689f04",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79933650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">535</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,095</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">535</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">286,760</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,360</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m535\u001b[0m)                 │           \u001b[38;5;34m9,095\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m535\u001b[0m)                 │         \u001b[38;5;34m286,760\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,360\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,215</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m301,215\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,215</span> (1.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301,215\u001b[0m (1.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(535,activation='relu',input_shape=(16,)))\n",
    "model.add(Dense(535,activation='relu'))\n",
    "model.add(Dense(n_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d838e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydot-ng in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydot-ng) (3.0.9)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydot-ng in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydot-ng) (3.0.9)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: graphviz in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (0.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot-ng\n",
    "!pip install pydot-ng\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2e3a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13cdba5",
   "metadata": {},
   "source": [
    "Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d1bdf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c47cd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 9, 8, 5, 4, 16, 7, 4, 24, 5, 17, 16, 21, 9, 25, 16, 5, 18, 19, 4, 17, 19, 16, 4, 2, 22, 16, 4, 19, 21, 15, 12, 0, 18, 5, 1, 25, 16, 8, 7, 1, 16, 22, 7, 12, 15, 3, 15, 15, 7, 15, 9, 4, 0, 11, 12, 9, 2, 24, 9, 7, 12, 25, 18, 5, 18, 15, 15, 9, 21, 12, 21, 24, 13, 12, 7, 6, 9, 15, 6, 20, 25, 11, 24, 9, 16, 4, 2, 10, 10, 7, 0, 19, 11, 14, 20, 13, 8, 15, 5, 5, 14, 17, 17, 10, 1, 0, 12, 0, 0, 18, 18, 7, 10, 9, 5, 11, 12, 20, 2, 6, 20, 13, 11, 7, 14, 1, 13, 8, 4, 15, 25, 3, 0, 0, 4, 4, 16, 14, 25, 20, 14, 11, 23, 16, 2, 4, 7, 17, 20, 14, 3, 12, 19, 10, 15, 5, 1, 12, 4, 7, 9, 19, 6, 24, 20, 22, 4, 9, 1, 19, 21, 9, 11, 1, 7, 5, 20, 12, 25, 17, 15, 18, 24, 3, 13, 3, 5, 14, 11, 5, 5, 0, 25, 24, 22, 0, 18, 5, 24, 7, 8, 7, 7, 15, 19, 22, 21, 21, 1, 5, 7, 6, 16, 9, 5, 16, 24, 0, 5, 24, 21, 4, 22, 25, 23, 18, 20, 7, 0, 19, 7, 24, 4, 8, 14, 12, 5, 23, 11, 4, 25, 11, 20, 3, 22, 9, 3, 12, 10, 12, 0, 1, 4, 18, 16, 7, 3, 0, 5, 7, 19, 21, 23, 19, 8, 21, 15, 19, 15, 1, 17, 9, 17, 25, 22, 23, 23, 20, 2, 15, 13, 10, 1, 22, 5, 14, 7, 9, 17, 21, 1, 2, 22, 14, 8, 15, 3, 20, 18, 6, 20, 7, 17, 14, 14, 9, 7, 14, 25, 15, 4, 24, 8, 5, 17, 11, 2, 22, 1, 15, 9, 24, 6, 18, 1, 23, 1, 13, 9, 19, 0, 19, 20, 17, 24, 18, 22, 4, 2, 1, 20, 5, 4, 20, 7, 10, 25, 14, 8, 21, 13, 6, 20, 13, 19, 24, 11, 16, 18, 7, 17, 7, 25, 5, 20, 20, 22, 20, 22, 18, 3, 18, 12, 5, 22, 4, 10, 23, 8, 13, 0, 5, 0, 5, 18, 11, 8, 7, 17, 5, 11, 0, 16, 23, 6, 21, 4, 22, 25, 18, 22, 11, 3, 9, 10, 25, 6, 23, 17, 3, 15, 9, 6, 2, 20, 2, 25, 7, 19, 6, 14, 6, 1, 2, 6, 4, 25, 10, 22, 2, 17, 17, 5, 25, 21, 15, 4, 18, 20, 5, 9, 22, 3, 9, 3, 2, 9, 18, 12, 13, 16, 11, 12, 6, 3, 3, 14, 15, 4, 22, 7, 12, 0, 22, 10, 20, 13, 15, 24, 9, 20, 22, 4, 11, 17, 20, 13, 6, 8, 17, 22, 6, 9, 2, 11, 22, 12, 14, 10, 6, 23, 23, 20, 22, 19, 0, 0, 11, 17, 23, 23, 5, 8, 25, 5, 3, 22, 6, 15, 4, 4, 9, 9, 14, 22, 20, 25, 16, 7, 23, 1, 18, 4, 10, 8, 16, 12, 2, 15, 22, 23, 18, 25, 5, 4, 23, 5, 12, 7, 7, 8, 16, 6, 8, 5, 18, 21, 25, 23, 10, 18, 14, 6, 7, 13, 24, 2, 24, 9, 4, 11, 5, 11, 16, 23, 13, 21, 24, 2, 7, 20, 12, 21, 24, 3, 0, 13, 6, 17, 19, 25, 4, 12, 2, 17, 16, 18, 13, 17, 12, 12, 24, 9, 20, 8, 8, 22, 18, 20, 14, 8, 16, 15, 15, 8, 2, 3, 17, 4, 14, 10, 17, 0, 0, 0, 18, 23, 16, 7, 2, 16, 10, 14, 16, 14, 13, 20, 19, 2, 22, 11, 16, 25, 15, 9, 13, 20, 11, 17, 20, 7, 0, 10, 6, 22, 10, 21, 5, 11, 24, 1, 11, 1, 15, 11, 16, 15, 16, 18, 24, 22, 17, 12, 24, 5, 22, 12, 24, 18, 13, 18, 23, 0, 24, 7, 16, 6, 20, 14, 4, 22, 4, 7, 15, 21, 20, 4, 22, 22, 2, 8, 11, 3, 2, 22, 22, 15, 21, 17, 16, 11, 24, 17, 2, 15, 23, 18, 10, 16, 9, 19, 13, 12, 22, 6, 23, 24, 19, 11, 5, 3, 4, 17, 24, 18, 4, 23, 24, 16, 20, 23, 4, 12, 19, 22, 22, 3, 1, 7, 25, 0, 8, 16, 16, 3, 1, 7, 22, 2, 8, 12, 0, 13, 11, 13, 17, 18, 17, 0, 20, 13, 1, 5, 7, 0, 2, 16, 15, 21, 9, 9, 6, 18, 4, 17, 18, 11, 18, 11, 15, 13, 2, 24, 11, 8, 4, 17, 18, 23, 11, 0, 15, 7, 6, 14, 7, 1, 12, 4, 23, 17, 10, 14, 25, 5, 23, 21, 20, 16, 4, 20, 17, 4, 4, 24, 19, 22, 23, 12, 16, 17, 7, 13, 10, 3, 11, 23, 12, 14, 11, 24, 7, 15, 11, 4, 17, 11, 9, 18, 23, 18, 11, 14, 9, 8, 3, 19, 18, 18, 5, 2, 5, 15, 14, 15, 22, 3, 14, 10, 10, 13, 5, 15, 11, 9, 20, 12, 0, 4, 10, 15, 5, 13, 24, 2, 13, 20, 9, 17, 16, 20, 14, 10, 3, 9, 9, 22, 11, 6, 13, 3, 14, 0, 14, 16, 7, 13, 13, 18, 22, 23, 24, 22, 22, 21, 18, 16, 0, 23, 3, 5, 14, 16, 14, 6, 20, 16, 0, 10, 3, 24, 24, 24, 15, 0, 1, 6, 5, 15, 0, 14, 2, 0, 13, 1, 10, 10, 13, 22, 2, 17, 16, 8, 20, 23, 9, 12, 11, 7, 17, 1, 23, 13, 3, 20, 15, 8, 25, 12, 21, 22, 4, 6, 19, 13, 21, 11, 15, 11, 8, 8, 22, 1, 5, 3, 21, 19, 3, 7, 15, 17, 0, 18, 20, 13, 11, 16, 4, 13, 21, 12, 22, 16, 9, 13, 17, 13, 3, 14, 8, 11, 5, 4, 20, 12, 25, 4, 11, 20, 5, 9, 5, 19, 15, 18, 10, 13, 0, 17, 19, 15, 11, 16, 25, 21, 1, 18, 7, 11, 2, 20, 5, 25, 13, 10, 5, 11, 16, 6, 8, 8, 6, 20, 4, 7, 12, 18, 11, 10, 14, 0, 2, 14, 0, 10, 6, 14, 17, 5, 22, 2, 21, 11, 15, 8, 11, 4, 6, 18, 10, 1, 20, 12, 18, 15, 7, 0, 17, 12, 6, 22, 1, 3, 9, 7, 2, 3, 3, 18, 1, 14, 19, 14, 12, 23, 9, 22, 9, 18, 10, 21, 9, 1, 0, 4, 20, 9, 9, 21, 21, 23, 20, 16, 15, 3, 20, 11, 5, 13, 24, 15, 25, 21, 25, 1, 2, 11, 17, 24, 7, 16, 12, 24, 2, 9, 7, 17, 3, 10, 7, 13, 10, 1, 22, 20, 14, 20, 16, 17, 25, 20, 7, 16, 24, 3, 23, 11, 8, 18, 23, 0, 19, 16, 9, 0, 15, 3, 7, 0, 6, 18, 23, 6, 10, 25, 16, 13, 25, 5, 8, 17, 10, 25, 6, 23, 1, 22, 1, 6, 18, 6, 24, 15, 11, 11, 0, 10, 10, 25, 20, 23, 3, 23, 24, 2, 3, 9, 24, 9, 23, 14, 23, 19, 9, 14, 11, 0, 6, 17, 13, 4, 14, 13, 3, 15, 25, 5, 5, 9, 2, 4, 7, 20, 4, 18, 7, 13, 3, 3, 16, 22, 16, 7, 0, 22, 16, 1, 23, 22, 11, 12, 12, 7, 15, 9, 7, 5, 10, 24, 11, 3, 15, 10, 2, 8, 8, 14, 16, 4, 19, 15, 7, 9, 2, 17, 2, 23, 0, 20, 3, 5, 17, 11, 3, 14, 2, 16, 19, 19, 18, 22, 20, 24, 20, 8, 6, 2, 0, 25, 15, 13, 14, 0, 8, 13, 4, 1, 24, 6, 22, 7, 2, 14, 11, 14, 6, 9, 20, 10, 17, 1, 7, 19, 7, 11, 25, 20, 7, 20, 17, 0, 21, 5, 2, 18, 20, 10, 13, 16, 18, 1, 24, 8, 5, 24, 18, 7, 24, 12, 2, 9, 18, 24, 25, 12, 11, 22, 11, 14, 8, 4, 3, 19, 13, 20, 11, 21, 14, 25, 5, 12, 19, 13, 15, 21, 13, 0, 21, 23, 5, 19, 9, 20, 4, 24, 6, 6, 0, 22, 23, 13, 1, 15, 0, 1, 10, 23, 0, 2, 16, 4, 2, 11, 16, 23, 0, 2, 24, 2, 19, 16, 0, 18, 19, 6, 15, 13, 4, 8, 18, 15, 18, 10, 5, 12, 22, 6, 1, 24, 17, 20, 24, 21, 7, 15, 9, 5, 13, 19, 0, 16, 17, 9, 9, 5, 3, 17, 23, 14, 19, 24, 1, 5, 20, 2, 11, 19, 2, 25, 7, 0, 13, 3, 11, 11, 3, 20, 22, 5, 20, 12, 18, 25, 25, 11, 1, 16, 16, 3, 17, 14, 19, 4, 0, 17, 25, 2, 3, 1, 20, 13, 1, 3, 4, 0, 18, 23, 11, 2, 12, 10, 8, 22, 5, 1, 24, 12, 14, 14, 7, 22, 19, 10, 22, 21, 20, 1, 11, 3, 23, 2, 8, 15, 19, 8, 25, 20, 20, 10, 1, 0, 4, 11, 16, 10, 2, 2, 17, 20, 24, 16, 11, 16, 23, 20, 20, 15, 0, 23, 19, 3, 3, 20, 13, 6, 2, 10, 19, 6, 14, 11, 1, 21, 16, 19, 9, 23, 2, 25, 6, 18, 3, 20, 21, 20, 9, 7, 16, 6, 20, 18, 13, 13, 11, 9, 10, 0, 21, 15, 2, 14, 3, 14, 23, 21, 5, 5, 3, 4, 13, 21, 23, 4, 19, 7, 10, 19, 4, 0, 16, 19, 24, 23, 14, 25, 16, 12, 6, 19, 18, 1, 2, 22, 22, 9, 7, 6, 20, 7, 10, 15, 14, 8, 18, 17, 0, 23, 4, 0, 19, 10, 2, 21, 2, 4, 5, 4, 16, 25, 12, 16, 19, 7, 3, 14, 20, 24, 25, 11, 3, 19, 17, 6, 13, 22, 2, 0, 14, 7, 14, 18, 4, 16, 14, 9, 0, 25, 14, 7, 12, 17, 11, 8, 24, 12, 10, 22, 21, 10, 5, 21, 7, 25, 1, 14, 16, 5, 3, 5, 17, 17, 16, 19, 19, 18, 2, 15, 15, 13, 0, 5, 18, 25, 13, 15, 24, 25, 10, 25, 22, 0, 2, 1, 21, 5, 16, 20, 22, 21, 15, 24, 9, 8, 8, 17, 10, 0, 15, 6, 2, 20, 1, 18, 14, 9, 0, 10, 8, 19, 14, 12, 3, 20, 22, 17, 24, 11, 0, 22, 18, 5, 15, 12, 23, 19, 24, 15, 24, 12, 15, 5, 11, 6, 7, 3, 25, 15, 25, 16, 16, 23, 12, 15, 6, 15, 4, 20, 12, 25, 23, 15, 21, 4, 16, 13, 22, 3, 22, 0, 20, 23, 0, 25, 14, 14, 13, 10, 22, 22, 15, 18, 5, 2, 18, 18, 12, 11, 14, 15, 25, 13, 10, 20, 25, 5, 16, 15, 2, 6, 18, 24, 23, 18, 8, 3, 0, 12, 13, 14, 23, 10, 7, 3, 19, 16, 24, 5, 22, 1, 21, 14, 2, 2, 11, 9, 11, 18, 4, 2, 0, 12, 11, 4, 25, 9, 23, 17, 17, 1, 12, 7, 13, 7, 23, 7, 5, 9, 0, 13, 0, 15, 9, 15, 20, 5, 15, 4, 16, 13, 14, 25, 9, 23, 19, 7, 6, 22, 0, 7, 11, 12, 12, 20, 2, 20, 0, 12, 14, 8, 2, 0, 22, 25, 1, 18, 15, 7, 7, 3, 15, 14, 9, 11, 23, 19, 25, 15, 0, 19, 3, 0, 0, 8, 24, 24, 14, 6, 8, 21, 16, 9, 15, 18, 22, 13, 19, 5, 21, 5, 15, 25, 5, 1, 21, 9, 20, 5, 0, 22, 24, 3, 11, 25, 5, 23, 1, 18, 7, 24, 1, 0, 0, 16, 18, 23, 22, 11, 15, 12, 9, 24, 19, 18, 11, 9, 22, 24, 6, 20, 7, 24, 16, 24, 18, 14, 2, 5, 13, 8, 23, 23, 7, 10, 12, 13, 12, 22, 24, 22, 22, 19, 3, 3, 18, 21, 20, 7, 18, 2, 14, 4, 22, 6, 24, 4, 22, 18, 17, 19, 20, 19, 15, 22, 18, 23, 18, 12, 0, 9, 4, 0, 2, 14, 17, 2, 23, 25, 2, 9, 24, 7, 15, 3, 15, 3, 9, 6, 20, 1, 14, 21, 2, 25, 5, 10, 22, 6, 16, 4, 13, 14, 21, 16, 20, 12, 4, 0, 17, 2, 20, 3, 24, 15, 25, 13, 16, 6, 18, 25, 11, 6, 16, 2, 1, 9, 12, 17, 21, 5, 4, 9, 24, 21, 23, 9, 2, 11, 13, 6, 18, 10, 21, 12, 2, 10, 5, 3, 5, 23, 16, 19, 14, 11, 22, 19, 17, 10, 15, 23, 6, 9, 1, 1, 0, 1, 22, 13, 24, 2, 20, 4, 18, 17, 11, 4, 24, 21, 19, 5, 19, 13, 10, 5, 15, 1, 14, 1, 10, 16, 25, 3, 11, 17, 17, 2, 5, 7, 0, 0, 15, 24, 19, 12, 20, 2, 12, 22, 12, 5, 2, 8, 23, 24, 3, 15, 13, 21, 20, 13, 18, 23, 0, 3, 2, 18, 8, 20, 0, 19, 12, 9, 6, 2, 21, 21, 25, 3, 11, 11, 9, 18, 21, 8, 18, 16, 15, 6, 2, 11, 14, 0, 13, 22, 13, 14, 4, 12, 4, 23, 22, 7, 22, 20, 8, 5, 15, 13, 0, 1, 1, 14, 1, 14, 4, 11, 9, 19, 6, 6, 23, 6, 7, 19, 21, 24, 19, 11, 23, 8, 20, 22, 9, 0, 16, 13, 18, 19, 7, 11, 1, 17, 7, 15, 1, 21, 4, 11, 22, 11, 25, 4, 25, 5, 21, 7, 25, 9, 1, 11, 18, 19, 7, 25, 5, 12, 7, 25, 0, 11, 23, 3, 11, 18, 25, 7, 9, 5, 3, 8, 20, 4, 17, 15, 7, 5, 21, 19, 8, 15, 19, 12, 16, 4, 23, 24, 15, 18, 19, 9, 22, 23, 22, 13, 23, 5, 14, 10, 1, 20, 5, 17, 4, 23, 24, 19, 16, 5, 20, 0, 24, 14, 19, 2, 12, 9, 5, 12, 16, 12, 16, 18, 24, 12, 9, 6, 1, 6, 13, 7, 22, 20, 3, 10, 9, 20, 6, 22, 5, 3, 17, 19, 10, 11, 0, 4, 4, 0, 15, 18, 14, 17, 25, 17, 3, 19, 2, 13, 15, 13, 22, 4, 9, 3, 0, 24, 6, 13, 21, 11, 0, 23, 23, 6, 5, 7, 6, 20, 22, 8, 10, 11, 12, 0, 20, 16, 9, 24, 3, 3, 3, 12, 11, 4, 2, 15, 9, 10, 8, 14, 5, 16, 4, 22, 4, 3, 17, 23, 9, 9, 22, 9, 22, 16, 2, 22, 6, 12, 21, 19, 5, 24, 20, 5, 6, 24, 22, 4, 0, 3, 6, 17, 14, 6, 6, 21, 5, 2, 23, 0, 13, 11, 18, 22, 25, 5, 5, 25, 24, 13, 19, 18, 18, 14, 20, 1, 9, 24, 7, 23, 2, 8, 23, 18, 9, 25, 16, 21, 18, 14, 18, 15, 20, 4, 15, 21, 20, 3, 4, 0, 15, 17, 1, 1, 7, 16, 23, 7, 22, 4, 24, 9, 13, 4, 6, 20, 10, 3, 22, 25, 4, 10, 1, 14, 3, 16, 7, 22, 19, 4, 10, 16, 8, 24, 2, 6, 5, 9, 21, 23, 14, 10, 16, 2, 9, 9, 4, 1, 11, 19, 25, 15, 25, 2, 14, 23, 14, 7, 2, 15, 6, 1, 7, 25, 5, 6, 24, 19, 0, 2, 19, 8, 21, 6, 2, 15, 9, 24, 20, 13, 17, 8, 14, 12, 19, 21, 16, 18, 16, 20, 25, 10, 14, 0, 2, 6, 0, 4, 13, 22, 10, 17, 6, 6, 1, 8, 20, 5, 14, 25, 18, 16, 10, 7, 11, 7, 2, 17, 21, 16, 5, 2, 16, 4, 16, 15, 22, 16, 16, 3, 11, 9, 15, 19, 1, 25, 14, 13, 20, 6, 16, 0, 8, 11, 20, 5, 15, 21, 17, 1, 17, 6, 24, 4, 9, 25, 9, 21, 24, 7, 0, 7, 17, 14, 7, 1, 23, 17, 13, 19, 18, 7, 20, 15, 22, 8, 3, 20, 7, 9, 7, 14, 16, 24, 8, 18, 19, 12, 24, 20, 0, 18, 21, 21, 10, 23, 19, 13, 15, 14, 23, 4, 2, 1, 17, 13, 0, 15, 21, 22, 5, 0, 14, 9, 5, 9, 16, 21, 6, 12, 16, 17, 10, 21, 3, 19, 21, 9, 14, 5, 25, 0, 10, 24, 10, 12, 1, 19, 25, 24, 23, 6, 2, 3, 10, 14, 14, 23, 5, 9, 4, 9, 7, 10, 5, 20, 8, 11, 11, 12, 1, 15, 10, 19, 8, 20, 10, 18, 9, 21, 10, 23, 24, 25, 16, 23, 14, 11, 19, 23, 9, 5, 4, 20, 0, 1, 16, 15, 10, 21, 24, 8, 9, 9, 4, 3, 7, 15, 24, 13, 20, 3, 12, 25, 9, 18, 5, 16, 3, 12, 3, 9, 13, 15, 25, 3, 12, 4, 8, 13, 15, 19, 4, 23, 2, 17, 21, 18, 13, 12, 25, 8, 16, 18, 11, 5, 0, 12, 5, 16, 24, 15, 9, 23, 12, 0, 19, 23, 20, 8, 10, 5, 9, 19, 3, 24, 16, 13, 21, 25, 7, 11, 0, 0, 1, 3, 22, 19, 19, 12, 3, 6, 14, 22, 8, 22, 18, 15, 17, 20, 3, 6, 4, 4, 22, 25, 5, 25, 4, 20, 15, 12, 23, 21, 22, 7, 16, 1, 0, 0, 3, 17, 16, 17, 8, 2, 20, 5, 13, 2, 16, 1, 14, 18, 0, 25, 8, 16, 5, 12, 17, 14, 8, 23, 22, 15, 15, 1, 7, 23, 12, 21, 0, 4, 7, 2, 17, 24, 23, 6, 1, 18, 11, 4, 2, 24, 3, 14, 22, 9, 12, 20, 4, 6, 9, 6, 6, 25, 11, 14, 3, 3, 18, 12, 23, 1, 10, 3, 25, 20, 5, 6, 14, 0, 7, 19, 7, 20, 4, 11, 12, 0, 19, 23, 16, 6, 2, 5, 8, 17, 10, 17, 9, 22, 20, 12, 2, 11, 6, 18, 6, 9, 25, 14, 20, 10, 22, 14, 0, 18, 23, 19, 16, 11, 15, 16, 21, 12, 19, 24, 24, 16, 13, 3, 4, 14, 1, 5, 20, 15, 24, 24, 14, 3, 18, 5, 8, 8, 17, 0, 19, 16, 3, 13, 2, 5, 10, 12, 6, 24, 1, 14, 19, 11, 1, 14, 5, 15, 4, 11, 13, 21, 19, 21, 1, 16, 22, 19, 6, 3, 6, 20, 13, 9, 2, 4, 5, 11, 18, 8, 21, 17, 9, 17, 22, 12, 10, 19, 11, 21, 13, 24, 18, 4, 13, 15, 17, 12, 23, 5, 11, 1, 13, 8, 6, 2, 14, 0, 14, 24, 4, 25, 24, 3, 14, 9, 23, 7, 14, 11, 17, 24, 9, 14, 3, 14, 5, 12, 21, 11, 6, 3, 18, 10, 10, 16, 7, 2, 9, 1, 19, 19, 23, 4, 0, 19, 15, 16, 2, 22, 6, 0, 2, 4, 8, 5, 1, 13, 6, 0, 9, 2, 3, 20, 14, 12, 9, 3, 12, 17, 1, 12, 23, 25, 20, 21, 20, 0, 8, 0, 10, 4, 15, 0, 7, 13, 25, 9, 21, 2, 16, 12, 9, 19, 22, 3, 7, 14, 10, 19, 14, 0, 8, 4, 21, 11, 5, 4, 20, 10, 17, 20, 16, 6, 13, 24, 2, 5, 3, 12, 17, 13, 11, 20, 0, 1, 19, 25, 14, 4, 20, 4, 18, 6, 6, 20, 10, 17, 10, 8, 5, 16, 19, 2, 12, 25, 7, 15, 23, 14, 19, 3, 14, 25, 20, 0, 18, 7, 2, 3, 11, 14, 2, 22, 14, 5, 2, 22, 13, 11, 13, 6, 23, 25, 1, 16, 15, 24, 15, 17, 18, 3, 13, 16, 11, 21, 2, 16, 0, 17, 17, 5, 10, 9, 19, 12, 21, 13, 25, 5, 23, 1, 25, 23, 25, 5, 0, 25, 17, 14, 17, 13, 0, 2, 12, 5, 8, 2, 0, 8, 19, 7, 17, 11, 15, 17, 4, 18, 4, 9, 7, 7, 2, 14, 20, 9, 15, 7, 25, 15, 4, 11, 22, 23, 17, 14, 8, 1, 13, 21, 22, 23, 16, 21, 17, 18, 11, 16, 18, 15, 20, 11, 19, 23, 17, 21, 18, 23, 14, 6, 17, 16, 7, 21, 0, 11, 24, 2, 23, 0, 24, 12, 20, 25, 2, 10, 24, 8, 22, 20, 21, 6, 25, 3, 25, 16, 15, 16, 3, 0, 24, 8, 16, 3, 13, 20, 21, 11, 12, 16, 6, 2, 19, 3, 18, 21, 9, 6, 2, 23, 5, 0, 11, 9, 12, 16, 10, 20, 0, 3, 13, 19, 0, 23, 9, 9, 20, 3, 24, 7, 19, 17, 3, 5, 21, 21, 17, 15, 21, 25, 12, 20, 0, 14, 16, 21, 14, 8, 7, 5, 16, 22, 17, 10, 14, 8, 12, 22, 4, 1, 7, 9, 7, 5, 0, 6, 5, 7, 9, 5, 19, 18, 7, 6, 11, 17, 21, 8, 9, 16, 11, 11, 17, 11, 12, 2, 4, 14, 8, 4, 14, 6, 7, 12, 14, 22, 21, 16, 24, 0, 0, 7, 2, 15, 4, 21, 6, 1, 9, 18, 21, 23, 21, 6, 20, 25, 21, 0, 24, 0, 9, 11, 10, 17, 15, 25, 1, 23, 21, 9, 14, 0, 0, 9, 12, 25, 1, 5, 12, 10, 10, 10, 12, 14, 13, 24, 20, 5, 16, 25, 1, 1, 9, 11, 6, 15, 19, 15, 23, 11, 18, 0, 22, 9, 15, 22, 4, 6, 6, 23, 1, 10, 21, 22, 7, 20, 1, 22, 6, 6, 1, 5, 13, 9, 7, 16, 20, 19, 15, 16, 1, 2, 15, 7, 2, 11, 22, 15, 2, 0, 18, 4, 3, 23, 3, 10, 12, 22, 15, 16, 15, 7, 11, 17, 19, 14, 15, 16, 18, 3, 14, 13, 16, 15, 5, 22, 17, 5, 6, 5, 11, 13, 0, 23, 23, 1, 0, 21, 25, 0, 12, 12, 25, 11, 12, 7, 20, 24, 18, 12, 21, 5, 20, 24, 16, 17, 11, 7, 5, 23, 22, 22, 17, 14, 13, 0, 5, 0, 0, 8, 5, 1, 25, 19, 0, 0, 16, 9, 7, 22, 22, 1, 19, 3, 3, 6, 14, 22, 1, 3, 25, 0, 10, 6, 4, 12, 1, 13, 8, 12, 18, 14, 15, 12, 10, 24, 5, 22, 8, 7, 18, 13, 13, 16, 3, 12, 10, 20, 24, 15, 16, 0, 22, 10, 4, 0, 25, 3, 2, 25, 15, 13, 3, 2, 8, 21, 3, 10, 12, 21, 15, 12, 15, 13, 24, 0, 16, 1, 14, 21, 24, 7, 18, 5, 2, 24, 24, 25, 13, 6, 18, 18, 2, 14, 1, 9, 20, 23, 22, 2, 24, 13, 19, 17, 23, 14, 6, 18, 7, 23, 4, 13, 20, 19, 25, 1, 15, 14, 15, 20, 21, 7, 9, 21, 4, 13, 6, 7, 18, 16, 4, 19, 14, 18, 20, 4, 13, 12, 3, 10, 5, 6, 13, 0, 18, 19, 12, 21, 7, 10, 10, 6, 11, 5, 23, 18, 20, 19, 16, 15, 1, 4, 3, 13, 16, 25, 15, 14, 9, 13, 14, 21, 24, 23, 14, 8, 16, 5, 14, 3, 23, 8, 4, 22, 4, 5, 21, 21, 14, 21, 24, 12, 2, 11, 18, 20, 2, 2, 23, 15, 6, 25, 2, 25, 12, 3, 9, 7, 14, 13, 20, 15, 3, 3, 19, 25, 9, 23, 6, 0, 12, 19, 25, 13, 20, 16, 4, 25, 16, 17, 16, 14, 14, 19, 10, 5, 15, 15, 18, 19, 12, 3, 12, 11, 0, 8, 14, 23, 11, 21, 16, 19, 20, 1, 18, 7, 8, 5, 20, 8, 18, 3, 22, 20, 11, 15, 20, 5, 19, 3, 12, 12, 5, 13, 1, 23, 19, 20, 23, 17, 23, 23, 20, 16, 21, 11, 1, 20, 10, 6, 12, 14, 22, 15, 12, 12, 8, 22, 24, 6, 20, 7, 19, 17, 9, 23, 11, 16, 17, 17, 20, 3, 16, 8, 0, 15, 23, 12, 18, 25, 4, 25, 0, 13, 22, 18, 23, 6, 15, 18, 9, 14, 25, 4, 6, 7, 16, 17, 10, 9, 11, 5, 21, 16, 0, 20, 23, 13, 18, 18, 0, 1, 2, 18, 14, 10, 9, 12, 15, 14, 17, 10, 16, 17, 0, 17, 17, 21, 11, 24, 9, 4, 8, 24, 16, 15, 1, 7, 18, 1, 12, 6, 14, 17, 10, 7, 19, 8, 14, 3, 2, 16, 9, 12, 1, 13, 12, 2, 9, 2, 11, 10, 0, 15, 14, 22, 9, 19, 5, 18, 3, 19, 20, 21, 16, 20, 21, 20, 21, 9, 22, 5, 20, 0, 10, 5, 22, 0, 15, 23, 15, 15, 24, 22, 3, 16, 25, 7, 6, 23, 20, 9, 12, 15, 9, 20, 6, 14, 13, 21, 2, 23, 9, 16, 16, 5, 0, 15, 13, 17, 24, 1, 9, 13, 0, 15, 23, 1, 23, 16, 6, 19, 11, 23, 18, 13, 11, 23, 4, 1, 22, 16, 13, 22, 9, 17, 7, 13, 25, 16, 6, 18, 17, 15, 16, 5, 17, 17, 1, 5, 20, 15, 5, 7, 19, 21, 3, 12, 24, 7, 13, 5, 3, 17, 22, 19, 20, 15, 14, 4, 7, 15, 0, 6, 13, 19, 13, 11, 18, 1, 15, 0, 15, 7, 22, 24, 5, 11, 2, 18, 9, 23, 18, 11, 5, 5, 17, 4, 2, 25, 9, 17, 15, 9, 5, 24, 12, 10, 2, 9, 15, 23, 20, 25, 6, 12, 10, 13, 17, 4, 6, 11, 2, 18, 6, 3, 20, 17, 23, 20, 19, 0, 3, 11, 0, 2, 21, 24, 2, 0, 13, 12, 20, 6, 13, 16, 23, 3, 20, 5, 15, 1, 9, 7, 7, 16, 3, 20, 17, 3, 0, 23, 17, 25, 23, 18, 20, 15, 16, 0, 10, 14, 19, 0, 10, 2, 1, 7, 15, 6, 13, 0, 17, 6, 7, 12, 20, 2, 3, 12, 20, 8, 16, 2, 0, 3, 18, 2, 3, 19, 11, 20, 5, 14, 7, 0, 13, 24, 9, 4, 2, 0, 18, 1, 1, 22, 7, 22, 19, 12, 9, 2, 2, 18, 12, 21, 25, 23, 16, 9, 6, 18, 1, 15, 24, 11, 23, 6, 14, 16, 6, 23, 21, 9, 21, 5, 3, 24, 24, 16, 19, 23, 24, 25, 8, 2, 25, 4, 4, 10, 3, 22, 9, 7, 25, 6, 5, 15, 11, 17, 4, 2, 6, 19, 15, 2, 23, 9, 17, 8, 14, 24, 25, 20, 2, 1, 7, 10, 17, 23, 16, 10, 7, 5, 11, 25, 6, 10, 5, 19, 1, 0, 7, 13, 12, 25, 25, 10, 24, 16, 7, 16, 16, 15, 19, 20, 24, 15, 17, 6, 19, 3, 2, 15, 15, 13, 2, 8, 13, 11, 5, 23, 8, 24, 3, 3, 10, 20, 12, 25, 0, 4, 18, 1, 22, 21, 13, 13, 14, 17, 1, 3, 15, 17, 18, 5, 22, 9, 25, 10, 1, 15, 23, 3, 11, 24, 23, 0, 20, 16, 23, 17, 1, 16, 17, 15, 16, 3, 13, 5, 1, 25, 1, 5, 10, 12, 21, 24, 15, 1, 15, 21, 10, 22, 4, 19, 20, 23, 20, 19, 24, 15, 15, 9, 0, 4, 13, 19, 22, 0, 11, 25, 6, 21, 12, 11, 3, 20, 1, 22, 14, 10, 6, 25, 9, 13, 14, 8, 22, 13, 23, 10, 25, 17, 6, 14, 24, 22, 8, 17, 25, 17, 15, 13, 5, 23, 14, 10, 22, 6, 3, 3, 22, 22, 1, 25, 18, 4, 23, 4, 10, 17, 14, 19, 12, 17, 7, 12, 13, 20, 24, 5, 14, 0, 8, 8, 22, 22, 2, 5, 1, 2, 4, 19, 8, 3, 23, 17, 10, 17, 13, 15, 21, 15, 22, 22, 23, 24, 8, 13, 6, 1, 16, 17, 14, 16, 2, 20, 20, 1, 10, 23, 3, 22, 11, 13, 22, 3, 16, 1, 22, 14, 6, 11, 22, 20, 0, 19, 16, 22, 15, 15, 1, 16, 2, 14, 3, 7, 16, 6, 25, 12, 1, 4, 24, 4, 16, 9, 3, 20, 24, 4, 24, 4, 15, 23, 0, 10, 3, 20, 18, 8, 13, 14, 6, 16, 12, 7, 7, 23, 2, 3, 2, 23, 3, 1, 21, 8, 21, 19, 21, 14, 14, 9, 21, 1, 25, 0, 13, 7, 15, 21, 21, 23, 5, 0, 0, 15, 10, 6, 10, 3, 4, 3, 14, 2, 19, 11, 16, 2, 19, 11, 16, 19, 11, 17, 13, 21, 7, 8, 8, 21, 17, 5, 2, 0, 0, 23, 16, 24, 14, 15, 9, 2, 24, 17, 15, 6, 15, 3, 24, 18, 15, 2, 20, 5, 21, 13, 6, 20, 17, 8, 23, 6, 25, 25, 2, 19, 24, 22, 4, 0, 25, 11, 5, 4, 24, 13, 10, 23, 16, 14, 4, 3, 13, 2, 4, 1, 23, 4, 24, 9, 0, 4, 9, 10, 25, 14, 18, 17, 23, 25, 25, 8, 14, 24, 5, 6, 21, 22, 11, 21, 6, 13, 9, 3, 18, 4, 4, 5, 23, 13, 21, 22, 4, 11, 8, 1, 21, 13, 23, 25, 16, 16, 21, 1, 11, 19, 1, 8, 12, 17, 4, 17, 3, 18, 1, 0, 9, 6, 12, 7, 2, 13, 4, 11, 19, 3, 8, 15, 25, 3, 14, 21, 3, 16, 7, 10, 4, 18, 13, 11, 6, 7, 16, 22, 16, 20, 18, 16, 1, 1, 6, 4, 24, 22, 23, 19, 1, 22, 3, 3, 15, 21, 19, 3, 9, 20, 4, 15, 19, 23, 23, 15, 8, 25, 5, 18, 11, 25, 23, 2, 0, 16, 18, 11, 22, 21, 3, 4, 6, 23, 13, 5, 14, 1, 23, 11, 1, 3, 14, 24, 14, 23, 11, 15, 5, 17, 5, 21, 18, 13, 9, 20, 25, 5, 18, 13, 2, 14, 4, 15, 2, 0, 17, 21, 20, 16, 15, 1, 2, 23, 22, 10, 13, 3, 3, 13, 8, 14, 3, 10, 5, 14, 17, 17, 16, 24, 20, 13, 9, 4, 14, 4, 5, 8, 10, 15, 1, 19, 23, 13, 6, 19, 22, 5, 24, 8, 13, 2, 10, 12, 4, 15, 8, 4, 0, 11, 15, 14, 11, 14, 17, 14, 20, 24, 11, 17, 16, 12, 0, 9, 19, 17, 19, 14, 12, 2, 16, 11, 21, 6, 18, 3, 1, 16, 21, 21, 1, 17, 9, 22, 22, 3, 6, 6, 16, 9, 2, 17, 8, 4, 15, 1, 12, 10, 19, 3, 15, 13, 8, 11, 19, 17, 4, 13, 24, 13, 20, 25, 7, 4, 8, 8, 21, 7, 17, 1, 2, 24, 4, 0, 21, 20, 11, 20, 8, 9, 2, 21, 8, 9, 24, 9, 3, 10, 20, 18, 14, 23, 2, 11, 13, 24, 18, 19, 5, 24, 18, 5, 2, 21, 17, 20, 6, 16, 23, 14, 20, 17, 25, 10, 5, 12, 1, 5, 13, 4, 19, 1, 10, 7, 21, 5, 11, 16, 24, 4, 4, 16, 16, 23, 24, 20, 19, 13, 10, 9, 6, 6, 6, 3, 4, 7, 3, 22, 24, 13, 21, 5, 18, 14, 21, 18, 3, 14, 5, 10, 6, 3, 11, 11, 2, 3, 20, 10, 15, 10, 1, 16, 1, 17, 23, 9, 13, 22, 7, 19, 6, 17, 21, 11, 24, 20, 18, 1, 20, 15, 16, 21, 19, 7, 14, 19, 15, 13, 21, 15, 1, 3, 18, 2, 12, 16, 0, 1, 21, 21, 12, 24, 15, 7, 14, 5, 13, 19, 19, 18, 8, 25, 2, 25, 17, 12, 21, 4, 5, 18, 14, 21, 18, 1, 0, 21, 4, 6, 13, 0, 11, 6, 5, 10, 14, 12, 8, 25, 17, 7, 8, 16, 19, 10, 24, 14, 10, 15, 22, 18, 11, 16, 10, 10, 7, 20, 19, 20, 16, 6, 1, 3, 7, 2, 15, 15, 0, 17, 10, 9, 14, 20, 25, 3, 8, 5, 14, 8, 6, 2, 24, 13, 10, 2, 9, 0, 7, 23, 25, 0, 13, 0, 12, 11, 5, 19, 3, 17, 14, 19, 6, 16, 9, 6, 18, 16, 22, 21, 9, 4, 22, 4, 23, 25, 3, 24, 18, 2, 2, 4, 5, 18, 24, 12, 17, 14, 19, 1, 23, 24, 25, 24, 15, 20, 3, 19, 6, 8, 24, 22, 2, 6, 24, 3, 21, 25, 23, 18, 11, 4, 21, 11, 3, 9, 12, 8, 10, 3, 11, 24, 0, 14, 6, 10, 0, 10, 24, 3, 9, 19, 15, 22, 17, 21, 1, 24, 19, 19, 20, 23, 23, 15, 25, 19, 10, 5, 1, 3, 10, 21, 14, 4, 3, 18, 18, 7, 17, 25, 13, 17, 16, 16, 14, 20, 22, 14, 18, 3, 4, 19, 10, 21, 18, 19, 21, 3, 19, 20, 16, 5, 17, 1, 12, 21, 14, 7, 15, 17, 7, 22, 6, 6, 4, 12, 0, 3, 19, 10, 12, 21, 6, 21, 22, 0, 22, 1, 22, 15, 6, 24, 19, 14, 10, 2, 10, 20, 5, 15, 25, 14, 14, 1, 3, 7, 7, 21, 7, 6, 11, 23, 15, 25, 11, 4, 25, 25, 24, 20, 24, 6, 5, 8, 16, 14, 1, 6, 1, 18, 16, 25, 22, 25, 10, 15, 5, 20, 14, 6, 15, 7, 25, 6, 16, 16, 22, 2, 3, 17, 3, 17, 12, 20, 22, 10, 2, 11, 24, 17, 25, 15, 23, 11, 0, 14, 2, 4, 1, 16, 24, 7, 6, 9, 24, 12, 20, 5, 21, 4, 8, 4, 1, 1, 7, 2, 24, 22, 10, 22, 9, 18, 6, 3, 25, 15, 24, 7, 0, 18, 12, 15, 13, 13, 2, 6, 20, 11, 16, 22, 18, 0, 15, 12, 9, 25, 0, 13, 13, 9, 7, 17, 18, 1, 0, 25, 6, 5, 6, 6, 13, 4, 15, 13, 14, 18, 17, 18, 15, 9, 9, 5, 17, 16, 0, 14, 11, 23, 21, 19, 16, 25, 16, 5, 14, 15, 20, 12, 18, 20, 20, 18, 19, 6, 4, 22, 13, 17, 18, 19, 15, 16, 21, 22, 23, 18, 4, 8, 25, 16, 11, 0, 10, 24, 14, 4, 7, 22, 25, 1, 15, 14, 0, 1, 16, 20, 5, 7, 3, 17, 19, 25, 10, 15, 19, 13, 6, 12, 10, 2, 9, 20, 21, 17, 2, 23, 15, 14, 23, 22, 15, 25, 13, 14, 9, 10, 12, 13, 23, 0, 23, 3, 15, 0, 20, 4, 13, 21, 2, 6, 6, 0, 15, 8, 19, 3, 23, 13, 8, 5, 20, 13, 12, 3, 14, 4, 13, 6, 13, 3, 15, 1, 2, 7, 4, 4, 21, 3, 20, 21, 22, 5, 18, 25, 12, 19, 21, 17, 18, 7, 2, 8, 15, 15, 5, 19, 11, 25, 17, 3, 0, 4, 19, 24, 21, 11, 15, 12, 10, 9, 11, 12, 4, 22, 22, 22, 0, 21, 24, 2, 6, 22, 10, 23, 9, 11, 24, 1, 2, 5, 21, 12, 8, 3, 7, 16, 3, 20, 22, 23, 13, 24, 12, 2, 3, 12, 17, 8, 3, 14, 8, 21, 19, 14, 1, 14, 15, 10, 3, 9, 1, 6, 2, 20, 1, 7, 10, 1, 24, 15, 16, 6, 12, 17, 19, 2, 24, 9, 6, 3, 14, 19, 23, 21, 1, 0, 3, 12, 12, 4, 14, 12, 20, 23, 23, 15, 7, 0, 2, 11, 17, 23, 15, 7, 18, 21, 23, 14, 3, 20, 11, 10, 5, 9, 17, 19, 12, 1, 9, 15, 9, 16, 23, 2, 20, 20, 0, 24, 0, 13, 6, 16, 21, 6, 10, 8, 11, 17, 7, 13, 13, 21, 19, 12, 15, 12, 0, 12, 17, 4, 5, 2, 21, 17, 10, 3, 14, 25, 11, 18, 23, 14, 15, 7, 9, 19, 23, 6, 14, 23, 14, 4, 15, 11, 15, 12, 6, 11, 13, 3, 20, 8, 18, 16, 13, 5, 19, 9, 21, 11, 25, 21, 1, 2, 23, 3, 12, 0, 24, 15, 17, 5, 3, 3, 0, 7, 17, 14, 18, 6, 1, 1, 23, 12, 16, 18, 16, 20, 24, 15, 8, 5, 5, 22, 7, 23, 20, 20, 21, 0, 24, 11, 16, 22, 5, 9, 24, 4, 5, 3, 12, 11, 13, 22, 9, 14, 5, 18, 15, 17, 1, 23, 24, 9, 9, 12, 7, 13, 19, 11, 2, 16, 4, 3, 23, 2, 14, 6, 0, 25, 5, 12, 13, 0, 16, 20, 16, 10, 6, 14, 4, 6, 8, 13, 18, 19, 13, 15, 14, 5, 11, 4, 19, 1, 6, 15, 5, 8, 10, 15, 21, 18, 7, 5, 21, 15, 2, 2, 14, 2, 2, 11, 9, 11, 22, 18, 0, 13, 0, 14, 18, 23, 7, 1, 12, 23, 24, 18, 1, 25, 19, 10, 3, 10, 16, 14, 20, 25, 14, 4, 16, 23, 22, 15, 7, 22, 18, 1, 18, 7, 21, 10, 21, 11, 14, 3, 11, 9, 12, 4, 19, 3, 6, 18, 2, 13, 1, 17, 15, 21, 20, 10, 1, 16, 0, 10, 5, 17, 18, 1, 20, 7, 15, 16, 2, 3, 25, 5, 23, 3, 0, 5, 12, 8, 18, 16, 20, 0, 24, 17, 7, 7, 12, 24, 1, 21, 23, 0, 12, 0, 20, 20, 9, 6, 1, 21, 13, 12, 13, 1, 2, 7, 15, 14, 19, 20, 15, 18, 24, 2, 13, 24, 20, 24, 5, 12, 25, 20, 10, 22, 18, 4, 9, 17, 3, 2, 9, 16, 23, 10, 15, 24, 25, 5, 21, 22, 4, 15, 0, 2, 23, 1, 9, 3, 22, 6, 19, 5, 11, 21, 25, 13, 16, 14, 1, 17, 24, 10, 10, 8, 1, 17, 7, 20, 14, 20, 11, 0, 1, 9, 6, 7, 23, 9, 1, 22, 4, 0, 15, 17, 4, 0, 3, 10, 18, 25, 24, 8, 20, 2, 9, 23, 17, 19, 14, 18, 0, 25, 14, 24, 13, 12, 11, 11, 2, 20, 13, 6, 10, 21, 1, 3, 7, 0, 19, 13, 6, 22, 16, 3, 9, 12, 25, 21, 21, 22, 5, 21, 24, 24, 13, 0, 20, 19, 0, 12, 15, 19, 16, 9, 24, 18, 22, 25, 6, 24, 18, 14, 0, 20, 0, 6, 14, 7, 14, 3, 17, 18, 9, 14, 20, 24, 13, 21, 2, 17, 19, 4, 19, 9, 4, 5, 20, 23, 9, 8, 12, 13, 3, 17, 25, 6, 19, 20, 14, 15, 9, 2, 21, 4, 6, 5, 16, 15, 14, 5, 12, 20, 3, 1, 25, 21, 12, 20, 12, 21, 25, 4, 11, 17, 15, 6, 13, 12, 0, 20, 19, 5, 20, 3, 9, 21, 3, 8, 14, 17, 5, 1, 3, 15, 2, 11, 5, 2, 18, 1, 9, 9, 5, 6, 11, 16, 23, 25, 25, 1, 12, 3, 0, 10, 18, 15, 18, 4, 17, 23, 9, 3, 10, 6, 6, 1, 25, 0, 18, 16, 20, 20, 24, 13, 21, 10, 1, 8, 15, 24, 4, 15, 18, 9, 15, 9, 10, 10, 7, 17, 1, 21, 5, 0, 22, 1, 16, 21, 9, 19, 9, 25, 22, 7, 3, 4, 21, 12, 5, 25, 23, 1, 7, 10, 21, 17, 2, 2, 3, 0, 17, 19, 4, 16, 15, 4, 4, 19, 1, 23, 1, 23, 21, 22, 12, 6, 11, 3, 25, 10, 20, 4, 7, 10, 1, 15, 0, 24, 17, 10, 13, 23, 13, 23, 4, 15, 15, 19, 0, 9, 17, 15, 19, 21, 16, 18, 4, 18, 24, 7, 18, 11, 17, 12, 0, 22, 5, 25, 21, 20, 2, 23, 2, 12, 6, 4, 16, 15, 3, 1, 0, 15, 1, 4, 14, 7, 14, 21, 11, 4, 12, 17, 0, 11, 14, 22, 14, 7, 17, 13, 16, 15, 20, 14, 14, 3, 11, 18, 24, 4, 2, 20, 10, 17, 18, 3, 19, 8, 17, 1, 4, 13, 7, 16, 14, 21, 20, 6, 23, 21, 2, 16, 18, 24, 20, 15, 7, 12, 16, 4, 13, 14, 17, 23, 12, 25, 25, 24, 4, 13, 21, 7, 0, 7, 3, 16, 25, 11, 9, 2, 20, 16, 23, 21, 3, 6, 15, 3, 23, 25, 12, 7, 16, 20, 4, 19, 10, 5, 12, 14, 3, 6, 14, 12, 2, 17, 2, 14, 2, 25, 3, 3, 21, 12, 25, 11, 5, 25, 4, 6, 20, 24, 5, 14, 7, 15, 3, 13, 4, 17, 20, 11, 12, 1, 6, 21, 21, 9, 18, 1, 20, 5, 7, 11, 10, 22, 6, 6, 1, 22, 24, 18, 9, 24, 8, 9, 22, 8, 9, 23, 23, 15, 22, 18, 4, 11, 8, 1, 21, 7, 10, 0, 0, 1, 4, 1, 8, 20, 24, 10, 24, 7, 21, 24, 0, 16, 24, 16, 2, 21, 16, 18, 20, 14, 13, 7, 3, 2, 9, 14, 13, 12, 5, 0, 0, 4, 7, 5, 12, 4, 8, 10, 17, 2, 10, 13, 7, 16, 4, 10, 7, 14, 17, 20, 8, 4, 16, 25, 14, 17, 19, 7, 3, 3, 18, 19, 23, 11, 12, 4, 24, 12, 17, 4, 14, 12, 22, 21, 20, 12, 17, 12, 20, 13, 16, 17, 10, 6, 19, 15, 24, 5, 3, 18, 15, 8, 22, 19, 17, 16, 24, 10, 3, 2, 25, 2, 24, 2, 2, 5, 15, 6, 16, 15, 15, 1, 10, 4, 15, 13, 2, 12, 1, 8, 18, 14, 16, 4, 17, 19, 17, 21, 23, 6, 6, 9, 21, 25, 24, 20, 5, 9, 7, 18, 20, 12, 1, 15, 20, 0, 21, 16, 19, 3, 0, 12, 17, 5, 2, 14, 13, 22, 12, 17, 25, 4, 13, 25, 11, 12, 11, 19, 3, 3, 23, 3, 10, 24, 10, 0, 7, 24, 7, 12, 3, 20, 22, 6, 2, 8, 20, 1, 5, 3, 1, 19, 15, 15, 20, 18, 9, 21, 4, 20, 24, 2, 5, 19, 19, 25, 22, 3, 10, 15, 9, 16, 19, 19, 8, 11, 9, 20, 24, 9, 19, 23, 19, 1, 4, 17, 11, 3, 19, 16, 16, 8, 4, 22, 10, 10, 25, 5, 11, 8, 8, 8, 11, 11, 23, 3, 11, 20, 21, 17, 23, 10, 13, 16, 25, 3, 19, 24, 12, 0, 8, 4, 9, 25, 22, 2, 17, 2, 13, 0, 7, 25, 12, 21, 17, 24, 2, 22, 21, 13, 7, 6, 11, 22, 12, 11, 5, 17, 8, 3, 21, 7, 0, 17, 3, 15, 6, 2, 19, 10, 8, 2, 6, 8, 4, 10, 5, 0, 10, 6, 23, 15, 0, 22, 14, 6, 13, 18, 24, 7, 11, 18, 19, 6, 14, 17, 16, 11, 10, 13, 11, 23, 15, 3, 15, 3, 19, 12, 21, 14, 15, 4, 11, 2, 2, 8, 9, 6, 21, 21, 0, 17, 11, 5, 0, 22, 24, 15, 1, 0, 16, 1, 17, 8, 7, 2, 14, 12, 4, 15, 16, 9, 19, 25, 15, 6, 5, 21, 11, 10, 19, 22, 2, 7, 1, 18, 7, 14, 8, 7, 20, 6, 12, 8, 4, 7, 14, 21, 22, 0, 16, 14, 2, 2, 17, 7, 1, 12, 8, 11, 9, 11, 0, 1, 2, 25, 20, 12, 25, 10, 22, 12, 24, 7, 1, 20, 12, 20, 20, 7, 17, 14, 18, 25, 13, 20, 25, 19, 13, 6, 20, 17, 3, 25, 15, 23, 12, 23, 11, 4, 7, 19, 10, 4, 14, 25, 25, 15, 19, 19, 9, 7, 6, 13, 6, 5, 9, 7, 3, 4, 21, 2, 7, 23, 9, 3, 9, 17, 12, 16, 6, 16, 18, 20, 0, 8, 2, 6, 19, 25, 20, 2, 14, 20, 25, 24, 15, 22, 12, 19, 19, 4, 24, 24, 0, 8, 9, 18, 8, 5, 12, 4, 11, 9, 2, 1, 24, 8, 6, 18, 11, 25, 11, 12, 2, 1, 24, 9, 17, 9, 6, 5, 18, 12, 2, 23, 14, 25, 15, 19, 9, 18, 18, 23, 20, 24, 23, 17, 12, 5, 15, 18, 14, 23, 19, 17, 0, 15, 17, 4, 3, 8, 14, 15, 19, 18, 23, 5, 4, 5, 4, 8, 22, 8, 8, 13, 0, 22, 24, 8, 11, 18, 3, 7, 18, 22, 18, 21, 8, 6, 25, 2, 24, 25, 1, 12, 15, 11, 22, 0, 14, 24, 25, 2, 23, 20, 23, 11, 19, 18, 23, 17, 0, 21, 10, 12, 5, 5, 18, 14, 18, 14, 14, 15, 16, 1, 9, 12, 13, 6, 23, 9, 25, 16, 22, 20, 22, 9, 3, 20, 24, 11, 7, 23, 13, 9, 11, 3, 7, 20, 17, 14, 22, 1, 0, 20, 12, 10, 8, 19, 23, 15, 2, 4, 5, 11, 12, 9, 1, 4, 11, 0, 16, 5, 18, 9, 4, 0, 11, 0, 24, 18, 8, 3, 3, 22, 1, 24, 23, 12, 6, 5, 0, 15, 14, 13, 20, 18, 14, 11, 13, 15, 1, 23, 1, 11, 18, 12, 25, 17, 0, 0, 0, 21, 14, 2, 5, 2, 15, 20, 1, 9, 12, 9, 11, 19, 12, 19, 6, 1, 24, 3, 17, 12, 5, 14, 21, 1, 24, 13, 2, 16, 11, 11, 14, 10, 7, 12, 1, 21, 2, 10, 17, 24, 11, 21, 24, 14, 21, 11, 2, 17, 5, 21, 21, 0, 22, 19, 21, 20, 6, 15, 13, 24, 7, 18, 25, 25, 12, 7, 14, 8, 16, 20, 8, 22, 21, 19, 15, 2, 22, 19, 16, 4, 23, 8, 17, 14, 16, 2, 16, 23, 4, 6, 4, 15, 19, 23, 12, 19, 22, 10, 12, 0, 6, 1, 13, 5, 14, 7, 2, 20, 20, 20, 1, 2, 7, 0, 10, 3, 14, 1, 18, 19, 21, 24, 19, 22, 23, 5, 20, 8, 23, 7, 9, 18, 11, 5, 6, 11, 4, 17, 24, 7, 21, 2, 1, 19, 17, 22, 7, 14, 13, 3, 12, 2, 0, 21, 1, 14, 10, 10, 8, 23, 2, 19, 0, 1, 5, 17, 11, 12, 16, 19, 13, 13, 3, 0, 19, 4, 21, 10, 23, 23, 10, 21, 24, 5, 11, 16, 16, 10, 20, 25, 19, 20, 14, 20, 18, 21, 13, 22, 25, 3, 23, 5, 19, 7, 8, 15, 23, 14, 18, 5, 15, 24, 25, 8, 15, 19, 10, 1, 16, 10, 13, 10, 22, 19, 10, 11, 14, 14, 25, 5, 12, 18, 9, 21, 20, 24, 20, 7, 15, 21, 13, 5, 22, 21, 11, 4, 5, 22, 1, 5, 9, 14, 16, 8, 15, 20, 17, 8, 25, 0, 7, 15, 25, 8, 24, 6, 16, 5, 10, 4, 1, 22, 20, 1, 25, 19, 23, 5, 1, 25, 5, 0, 1, 2, 8, 8, 22, 13, 14, 11, 19, 2, 22, 13, 2, 5, 16, 19, 2, 22, 4, 21, 13, 14, 20, 22, 7, 19, 18, 17, 3, 14, 14, 25, 1, 17, 23, 12, 19, 6, 18, 20, 18, 9, 10, 15, 24, 4, 21, 2, 20, 10, 12, 3, 3, 13, 24, 5, 15, 25, 9, 24, 6, 9, 19, 9, 21, 24, 12, 24, 5, 8, 1, 3, 18, 10, 12, 13, 7, 21, 6, 22, 3, 5, 24, 0, 18, 5, 10, 17, 17, 3, 23, 21, 22, 19, 12, 5, 22, 16, 19, 10, 1, 6, 22, 18, 13, 19, 21, 11, 19, 18, 24, 19, 17, 11, 12, 4, 20, 24, 7, 13, 13, 23, 15, 5, 3, 8, 21, 14, 4, 15, 11, 15, 1, 8, 24, 12, 7, 21, 5, 3, 5, 25, 12, 1, 25, 2, 17, 16, 6, 8, 0, 18, 12, 3, 21, 3, 7, 2, 13, 0, 9, 11, 17, 5, 22, 16, 11, 13, 21, 17, 20, 14, 24, 5, 20, 20, 5, 2, 18, 7, 0, 7, 23, 19, 1, 20, 13, 22, 14, 16, 19, 20, 11, 13, 22, 10, 24, 0, 17, 11, 4, 10, 14, 18, 11, 14, 5, 24, 4, 15, 17, 21, 2, 11, 6, 20, 21, 1, 0, 17, 1, 15, 14, 12, 14, 2, 10, 2, 15, 22, 17, 10, 14, 3, 23, 5, 10, 17, 0, 22, 16, 3, 15, 24, 23, 17, 0, 1, 15, 9, 17, 2, 11, 24, 0, 19, 14, 24, 12, 18, 4, 8, 25, 9, 10, 18, 24, 1, 2, 16, 19, 24, 23, 6, 12, 4, 18, 22, 22, 3, 0, 24, 7, 4, 8, 20, 12, 12, 18, 3, 15, 25, 7, 7, 23, 24, 1, 5, 16, 12, 20, 1, 4, 0, 24, 14, 16, 23, 17, 20, 6, 25, 6, 24, 4, 15, 5, 3, 4, 18, 19, 1, 17, 20, 9, 9, 18, 19, 5, 22, 1, 3, 5, 16, 16, 13, 14, 10, 16, 15, 16, 4, 6, 10, 16, 9, 18, 5, 23, 15, 7, 11, 16, 4, 20, 2, 15, 10, 3, 19, 8, 17, 18, 13, 1, 24, 13, 23, 13, 6, 12, 17, 14, 21, 16, 13, 2, 22, 18, 19, 20, 12, 6, 12, 11, 1, 2, 9, 19, 23, 0, 17, 14, 23, 21, 15, 10, 10, 21, 2, 4, 24, 25, 0, 14, 17, 23, 11, 19, 19, 5, 11, 12, 12, 2, 6, 10, 21, 13, 21, 12, 10, 17, 21, 4, 6, 6, 18, 1, 10, 19, 17, 9, 18, 4, 10, 22, 20, 18, 0, 23, 0, 25, 21, 19, 15, 11, 22, 7, 3, 19, 24, 8, 0, 12, 24, 4, 3, 7, 21, 7, 12, 17, 1, 9, 6, 15, 1, 15, 12, 21, 12, 18, 11, 24, 14, 15, 18, 18, 14, 13, 22, 11, 10, 12, 10, 6, 3, 7, 2, 21, 24, 18, 12, 13, 24, 20, 5, 0, 20, 20, 1, 13, 3, 5, 4, 0, 5, 10, 21, 21, 18, 5, 0, 20, 1, 10, 18, 5, 20, 5, 5, 0, 18, 11, 20, 5, 19, 24, 7, 6, 3, 5, 7, 1, 9, 10, 14, 23, 15, 7, 4, 14, 5, 0, 12, 3, 0, 7, 16, 19, 1, 0, 14, 16, 4, 4, 14, 8, 2, 24, 13, 3, 20, 11, 0, 9, 13, 7, 24, 4, 14, 5, 16, 12, 3, 6, 6, 4, 2, 21, 6, 1, 19, 6, 0, 10, 18, 10, 19, 3, 9, 20, 18, 16, 8, 1, 18, 0, 21, 11, 0, 18, 13, 17, 21, 10, 19, 22, 24, 11, 5, 3, 4, 18, 17, 16, 10, 7, 5, 3, 23, 16, 18, 18, 6, 21, 24, 1, 17, 3, 12, 18, 18, 6, 19, 17, 16, 1, 23, 11, 4, 0, 25, 8, 14, 12, 5, 11, 11, 20, 5, 23, 19, 15, 24, 13, 10, 18, 0, 16, 20, 1, 12, 13, 23, 4, 23, 20, 10, 14, 7, 24, 7, 6, 0, 24, 21, 12, 15, 13, 20, 23, 22, 22, 0, 1, 8, 1, 20, 0, 1, 13, 23, 1, 9, 4, 16, 6, 7, 23, 15, 1, 11, 15, 24, 25, 21, 1, 15, 2, 20, 5, 12, 10, 5, 1, 13, 11, 24, 5, 1, 23, 9, 20, 16, 8, 12, 11, 22, 3, 13, 10, 19, 7, 25, 15, 25, 13, 18, 2, 21, 25, 18, 2, 23, 16, 18, 1, 22, 16, 2, 25, 5, 13, 1, 3, 3, 0, 20, 1, 16, 15, 5, 13, 5, 23, 5, 4, 22, 9, 17, 2, 19, 23, 2, 19, 18, 2, 0, 23, 20, 13, 20, 4, 1, 19, 9, 15, 5, 13, 21, 9, 13, 1, 14, 13, 16, 4, 21, 5, 11, 11, 4, 10, 21, 3, 6, 7, 7, 3, 24, 22, 5, 15, 0, 3, 17, 6, 14, 24, 25, 10, 5, 15, 21, 9, 19, 3, 6, 8, 24, 18, 25, 3, 9, 3, 11, 18, 19, 14, 12, 2, 4, 20, 14, 11, 0, 11, 2, 4, 23, 10, 21, 12, 0, 6, 12, 4, 12, 15, 8, 0, 3, 4, 20, 13, 7, 18, 24, 10, 4, 2, 23, 10, 20, 10, 19, 23, 5, 21, 20, 5, 5, 10, 5, 13, 23, 2, 25, 21, 7, 5, 12, 19, 23, 12, 7, 16, 23, 12, 12, 12, 9, 8, 3, 1, 23, 18, 15, 6, 17, 3, 1, 16, 16, 10, 24, 9, 22, 17, 13, 12, 13, 24, 22, 3, 20, 19, 3, 6, 11, 15, 15, 10, 17, 1, 10, 21, 5, 3, 5, 22, 1, 21, 20, 21, 19, 25, 18, 2, 17, 17, 1, 20, 19, 24, 4, 16, 1, 9, 5, 14, 24, 11, 4, 6, 18, 13, 20, 20, 1, 13, 19, 11, 22, 1, 12, 23, 6, 13, 9, 3, 1, 4, 15, 10, 10, 9, 22, 0, 23, 14, 17, 10, 24, 9, 21, 5, 10, 24, 22, 19, 22, 13, 19, 2, 5, 6, 16, 13, 8, 5, 2, 16, 6, 9, 6, 19, 17, 21, 22, 1, 22, 20, 14, 12, 23, 19, 17, 10, 11, 10, 2, 3, 13, 7, 16, 20, 2, 21, 2, 6, 20, 17, 14, 1, 18, 0, 0, 1, 2, 24, 15, 13, 2, 19, 18, 9, 19, 5, 2, 6, 5, 7, 25, 11, 9, 15, 3, 22, 19, 12, 9, 16, 9, 2, 9, 16, 9, 3, 2, 8, 21, 2, 25, 17, 1, 7, 23, 22, 7, 2, 14, 13, 12, 6, 18, 23, 2, 4, 0, 20, 14, 6, 7, 16, 14, 12, 10, 15, 16, 12, 23, 20, 18, 6, 5, 24, 0, 4, 4, 16, 10, 18, 21, 15, 7, 24, 2, 6, 22, 9, 8, 20, 17, 7, 15, 15, 11, 7, 6, 12, 1, 24, 21, 18, 4, 18, 0, 8, 24, 10, 0, 10, 17, 23, 8, 4, 4, 0, 0, 1, 1, 20, 4, 12, 23, 19, 15, 1, 15, 7, 22, 1, 12, 15, 15, 21, 7, 19, 9, 3, 11, 8, 2, 1, 15, 15, 12, 5, 25, 0, 21, 24, 13, 8, 6, 17, 1, 23, 16, 8, 5, 24, 4, 9, 16, 16, 21, 24, 0, 16, 0, 24, 8, 18, 13, 19, 12, 25, 17, 0, 19, 14, 24, 1, 14, 15, 0, 7, 9, 21, 3, 22, 3, 2, 23, 9, 9, 17, 22, 21, 11, 7, 4, 23, 9, 11, 18, 3, 20, 22, 7, 25, 15, 9, 18, 11, 3, 12, 2, 5, 19, 3, 5, 0, 17, 1, 10, 17, 25, 0, 7, 14, 22, 11, 6, 22, 12, 20, 15, 4, 21, 0, 6, 2, 3, 2, 0, 0, 19, 12, 3, 3, 21, 1, 22, 17, 18, 5, 9, 2, 12, 18, 19, 1, 9, 8, 2, 17, 0, 19, 3, 13, 23, 4, 14, 18, 22, 16, 3, 15, 2, 24, 5, 15, 1, 6, 12, 4, 7, 18, 12, 1, 8, 15, 19, 1, 8, 5, 10, 19, 17, 10, 5, 5, 13, 7, 7, 0, 4, 24, 17, 21, 0, 15, 13, 11, 3, 8, 21, 24, 8, 7, 23, 15, 11, 25, 6, 22, 24, 13, 10, 0, 20, 16, 5, 21, 15, 23, 15, 24, 12, 8, 21, 21, 19, 1, 13, 0, 20, 19, 7, 13, 17, 16, 2, 2, 5, 2, 18, 11, 3, 19, 23, 18, 24, 6, 5, 12, 24, 9, 10, 23, 2, 24, 12, 11, 12, 3, 20, 10, 1, 22, 3, 2, 23, 13, 18, 18, 13, 4, 2, 4, 7, 5, 22, 25, 23, 4, 5, 20, 17, 21, 20, 6, 22, 14, 16, 23, 3, 13, 13, 13, 18, 3, 11, 22, 24, 18, 16, 0, 5, 10, 19, 11, 17, 4, 23, 5, 12, 10, 1, 10, 13, 2, 1, 1, 2, 4, 20, 18, 17, 20, 6, 3, 23, 6, 9, 19, 17, 25, 20, 3, 0, 0, 9, 1, 7, 2, 5, 4, 17, 18, 22, 23, 14, 11, 9, 6, 15, 22, 20, 7, 0, 25, 6, 25, 23, 9, 8, 16, 17, 7, 0, 13, 19, 3, 20, 14, 1, 22, 7, 10, 19, 25, 23, 19, 10, 7, 19, 7, 12, 25, 6, 22, 10, 9, 10, 17, 13]\n"
     ]
    }
   ],
   "source": [
    "act=[]\n",
    "for i in range(len(y_test)):\n",
    "  act.append(np.argmax(y_test[i]))\n",
    "print(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbbd440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9334, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9833a13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for i in range(len(y_pred)):\n",
    "  pred.append(np.argmax(y_pred[i]))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74fbfc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03899721448467967"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(act,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f690962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "657c4313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       393\n",
      "           1       0.04      1.00      0.08       364\n",
      "           2       0.00      0.00      0.00       366\n",
      "           3       0.00      0.00      0.00       387\n",
      "           4       0.00      0.00      0.00       360\n",
      "           5       0.00      0.00      0.00       396\n",
      "           6       0.00      0.00      0.00       345\n",
      "           7       0.00      0.00      0.00       348\n",
      "           8       0.00      0.00      0.00       252\n",
      "           9       0.00      0.00      0.00       348\n",
      "          10       0.00      0.00      0.00       327\n",
      "          11       0.00      0.00      0.00       352\n",
      "          12       0.00      0.00      0.00       365\n",
      "          13       0.00      0.00      0.00       352\n",
      "          14       0.00      0.00      0.00       376\n",
      "          15       0.00      0.00      0.00       412\n",
      "          16       0.00      0.00      0.00       376\n",
      "          17       0.00      0.00      0.00       353\n",
      "          18       0.00      0.00      0.00       365\n",
      "          19       0.00      0.00      0.00       368\n",
      "          20       0.00      0.00      0.00       408\n",
      "          21       0.00      0.00      0.00       352\n",
      "          22       0.00      0.00      0.00       344\n",
      "          23       0.00      0.00      0.00       361\n",
      "          24       0.00      0.00      0.00       358\n",
      "          25       0.00      0.00      0.00       306\n",
      "\n",
      "    accuracy                           0.04      9334\n",
      "   macro avg       0.00      0.04      0.00      9334\n",
      "weighted avg       0.00      0.04      0.00      9334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(act,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41b4061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (3.5.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2aee16f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (3.5.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Name: keras\n",
      "Version: 3.5.0\n",
      "Summary: Multi-backend Keras.\n",
      "Home-page: https://github.com/keras-team/keras\n",
      "Author: Keras team\n",
      "Author-email: keras-users@googlegroups.com\n",
      "License: Apache License 2.0\n",
      "Location: C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "Requires: absl-py, h5py, ml-dtypes, namex, numpy, optree, packaging, rich\n",
      "Required-by: scikeras, tensorflow-intel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #version, 3.3.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.17.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #Version:, 2.16.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.5.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: BSD 3-Clause License\n",
      "\n",
      "Copyright (c) 2007-2024 The scikit-learn developers.\n",
      "All rights reserved.\n",
      "\n",
      "Redistribution and use in source and binary forms, with or without\n",
      "modification, are permitted provided that the following conditions are met:\n",
      "\n",
      "* Redistributions of source code must retain the above copyright notice, this\n",
      "  list of conditions and the following disclaimer.\n",
      "\n",
      "* Redistributions in binary form must reproduce the above copyright notice,\n",
      "  this list of conditions and the following disclaimer in the documentation\n",
      "  and/or other materials provided with the distribution.\n",
      "\n",
      "* Neither the name of the copyright holder nor the names of its\n",
      "  contributors may be used to endorse or promote products derived from\n",
      "  this software without specific prior written permission.\n",
      "\n",
      "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "Location: C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: imbalanced-learn, mlxtend, scikeras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Package(s) not found: #Version:, 1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade keras\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install --upgrade scikit-learn\n",
    "\n",
    "!pip show keras #version 3.3.3\n",
    "!pip show tensorflow #Version: 2.16.1\n",
    "!pip show scikit-learn #Version: 1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73f0917c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikeras in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from scikeras) (3.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from scikeras) (1.5.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (23.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6788b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(units, learning_rate):\n",
    "    # Your Keras model definition here, using units and learning_rate\n",
    "    model = Sequential()\n",
    "    # ... (model architecture)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='...')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "11850262",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'units': [16, 32, 64],  # List of possible units values\n",
    "    'learning_rate': [0.001, 0.01, 0.1]  # List of possible learning rate values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4aa74e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a7ebe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "# Assuming your model is defined as 'model'\n",
    "model_wrapper = KerasClassifier(build_fn=lambda: model, verbose=0)\n",
    "\n",
    "# Now you can use the model_wrapper in scikit-learn pipelines or GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6470b1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function &lt;lambda&gt; at 0x000001A9E849F4C0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;KerasClassifier<span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function &lt;lambda&gt; at 0x000001A9E849F4C0&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tclass_weight=None\n",
       ")</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=<function <lambda> at 0x000001A9E849F4C0>\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
